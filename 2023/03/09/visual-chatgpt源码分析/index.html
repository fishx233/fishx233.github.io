<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="visual-chatgpt源码分析"><meta name="keywords" content=""><meta name="author" content="fish"><meta name="copyright" content="fish"><title>visual-chatgpt源码分析 | fish</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '6.3.0'
} </script><meta name="generator" content="Hexo 6.3.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%88%E6%9E%9C"><span class="toc-number">1.</span> <span class="toc-text"> 效果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E6%9E%90"><span class="toc-number">2.</span> <span class="toc-text"> 分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%89%A9%E5%B1%95%E9%98%85%E8%AF%BB"><span class="toc-number">3.</span> <span class="toc-text"> 扩展阅读</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#langchain"><span class="toc-number">3.1.</span> <span class="toc-text"> langchain</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">3.1.1.</span> <span class="toc-text"> 简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#agent"><span class="toc-number">3.1.2.</span> <span class="toc-text"> agent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tools"><span class="toc-number">3.1.3.</span> <span class="toc-text"> tools</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#llama_index"><span class="toc-number">3.2.</span> <span class="toc-text"> llama_index</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%9D%E8%80%83"><span class="toc-number">4.</span> <span class="toc-text"> 思考</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">5.</span> <span class="toc-text"> 参考资料</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/media/44b726fcde934f76ac03a9a019fbb060.jpeg"></div><div class="author-info__name text-center">fish</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">9</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">7</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/media/101485281_p0_master1200.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">fish</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">visual-chatgpt源码分析</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-03-09</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/GPT/">GPT</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><meta name="referrer" content="no-referrer" />
# 概要
<p>使用chatgpt连接一系列模型，支持聊天期间发送和接收图像。从实际代码上看就是LLM+工具箱，简称缝合怪。代码基于早期版本，可能现在有所不同。</p>
<h1 id="效果"><a class="markdownIt-Anchor" href="#效果"></a> 效果</h1>
<p>反手就去github上偷一张图<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/1487474/1691812437359-fb4f8c78-49a8-4eb7-bcb2-e4c85c934998.png#averageHue=%23af9a84&amp;clientId=u724c9408-4af4-4&amp;from=paste&amp;id=u640c1b8a&amp;originHeight=1186&amp;originWidth=1504&amp;originalType=url&amp;ratio=1.5&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=udad6b98f-8820-4d88-af50-6a7dc865874&amp;title=" alt="" /><br />
<a name="OdubV"></a></p>
<h1 id="分析"><a class="markdownIt-Anchor" href="#分析"></a> 分析</h1>
<p><strong>硬编码的咒语</strong><br />先看一段硬编码的chatGPT的对话，看这一段内容，其实就可以把实现猜个八九不离十了，这段内容对LLM设定了一系列规则，并引导他使用工具列表来帮助他完成视觉能力。<br />变量说明：<br />tool_names：工具列表，[<a target="_blank" rel="noopener" href="http://tool.name">tool.name</a>, <a target="_blank" rel="noopener" href="http://tool.name">tool.name</a>]<br />ai_prefix：ai的对话前缀，默认填充AI。<br />chat_history：这里会填充对话历史<br />input：这个是最新的输入<br />agent_scratchpad：会暂存工具使用的中间对话</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">VISUAL_CHATGPT_PREFIX = <span class="string">&quot;&quot;&quot;Visual ChatGPT is designed to be able to assist with a wide range of text and visual related tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. Visual ChatGPT is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.</span></span><br><span class="line"><span class="string">Visual ChatGPT is able to process and understand large amounts of text and images. As a language model, Visual ChatGPT can not directly read images, but it has a list of tools to finish different visual tasks. Each image will have a file name formed as &quot;image/xxx.png&quot;, and Visual ChatGPT can invoke different tools to indirectly understand pictures. When talking about images, Visual ChatGPT is very strict to the file name and will never fabricate nonexistent files. When using tools to generate new image files, Visual ChatGPT is also known that the image may not be the same as the user&#x27;s demand, and will use other visual question answering tools or description tools to observe the real image. Visual ChatGPT is able to use tools in a sequence, and is loyal to the tool observation outputs rather than faking the image content and image file name. It will remember to provide the file name from the last tool observation, if a new image is generated.</span></span><br><span class="line"><span class="string">Human may provide new figures to Visual ChatGPT with a description. The description helps Visual ChatGPT to understand this image, but Visual ChatGPT should use tools to finish following tasks, rather than directly imagine from the description.</span></span><br><span class="line"><span class="string">Overall, Visual ChatGPT is a powerful visual dialogue assistant tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. </span></span><br><span class="line"><span class="string">TOOLS:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Visual ChatGPT  has access to the following tools:&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">VISUAL_CHATGPT_FORMAT_INSTRUCTIONS = <span class="string">&quot;&quot;&quot;To use a tool, please use the following format:</span></span><br><span class="line"><span class="string">​```</span></span><br><span class="line"><span class="string">Thought: Do I need to use a tool? Yes</span></span><br><span class="line"><span class="string">Action: the action to take, should be one of [&#123;tool_names&#125;]</span></span><br><span class="line"><span class="string">Action Input: the input to the action</span></span><br><span class="line"><span class="string">Observation: the result of the action</span></span><br><span class="line"><span class="string">​```</span></span><br><span class="line"><span class="string">When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:</span></span><br><span class="line"><span class="string">​```</span></span><br><span class="line"><span class="string">Thought: Do I need to use a tool? No</span></span><br><span class="line"><span class="string">&#123;ai_prefix&#125;: [your response here]</span></span><br><span class="line"><span class="string">​```</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">VISUAL_CHATGPT_SUFFIX = <span class="string">&quot;&quot;&quot;You are very strict to the filename correctness and will never fake a file name if it does not exist.</span></span><br><span class="line"><span class="string">You will remember to provide the image file name loyally if it&#x27;s provided in the last tool observation.</span></span><br><span class="line"><span class="string">Begin!</span></span><br><span class="line"><span class="string">Previous conversation history:</span></span><br><span class="line"><span class="string">&#123;chat_history&#125;</span></span><br><span class="line"><span class="string">New input: &#123;input&#125;</span></span><br><span class="line"><span class="string">Since Visual ChatGPT is a text language model, Visual ChatGPT must use tools to observe images rather than imagination.</span></span><br><span class="line"><span class="string">The thoughts and observations are only visible for Visual ChatGPT, Visual ChatGPT should remember to repeat important information in the final response for Human. </span></span><br><span class="line"><span class="string">Thought: Do I need to use a tool? &#123;agent_scratchpad&#125;&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>最终拼接的模版大致如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;prefix&#125;  <span class="comment"># 上一个代码块的VISUAL_CHATGPT_PREFIX内容</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># 工具列表内容，长这样 </span></span><br><span class="line"><span class="string">tool.name: tool.description</span></span><br><span class="line"><span class="string">tool.name: tool.description</span></span><br><span class="line"><span class="string">tool.name: tool.description</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">&#123;tool_strings&#125; </span><br><span class="line"></span><br><span class="line">&#123;format_instructions&#125; <span class="comment"># 上一个代码块的VISUAL_CHATGPT_FORMAT_INSTRUCTIONS内容</span></span><br><span class="line"></span><br><span class="line">&#123;suffix&#125; <span class="comment"># 上一个代码块的VISUAL_CHATGPT_SUFFIX内容</span></span><br></pre></td></tr></table></figure>
<p><strong>发送文本</strong><br />文本内容就比较简单直接发送对话</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run_text</span>(<span class="params">self, text, state</span>):</span><br><span class="line">    self.agent.memory.buffer = cut_dialogue_history(self.agent.memory.buffer, keep_last_n_words=<span class="number">500</span>)</span><br><span class="line">    res = self.agent(&#123;<span class="string">&quot;input&quot;</span>: text&#125;)</span><br><span class="line">    res[<span class="string">&#x27;output&#x27;</span>] = res[<span class="string">&#x27;output&#x27;</span>].replace(<span class="string">&quot;\\&quot;</span>, <span class="string">&quot;/&quot;</span>)</span><br><span class="line">    response = re.sub(<span class="string">&#x27;(image/\S*png)&#x27;</span>, <span class="keyword">lambda</span> m: <span class="string">f&#x27;![](/file=<span class="subst">&#123;m.group(<span class="number">0</span>)&#125;</span>)*<span class="subst">&#123;m.group(<span class="number">0</span>)&#125;</span>*&#x27;</span>, res[<span class="string">&#x27;output&#x27;</span>])</span><br><span class="line">    state = state + [(text, response)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\nProcessed run_text, Input text: <span class="subst">&#123;text&#125;</span>\nCurrent state: <span class="subst">&#123;state&#125;</span>\n&quot;</span></span><br><span class="line">          <span class="string">f&quot;Current Memory: <span class="subst">&#123;self.agent.memory.buffer&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">return</span> state, state</span><br></pre></td></tr></table></figure>
<p><strong>发送图片</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run_image</span>(<span class="params">self, image, state, txt</span>):</span><br><span class="line">    image_filename = os.path.join(<span class="string">&#x27;image&#x27;</span>, <span class="built_in">str</span>(uuid.uuid4())[<span class="number">0</span>:<span class="number">8</span>] + <span class="string">&quot;.png&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;======&gt;Auto Resize Image...&quot;</span>)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(image.name)</span><br><span class="line">    width, height = img.size</span><br><span class="line">    ratio = <span class="built_in">min</span>(<span class="number">512</span> / width, <span class="number">512</span> / height)</span><br><span class="line">    width_new, height_new = (<span class="built_in">round</span>(width * ratio), <span class="built_in">round</span>(height * ratio))</span><br><span class="line">    width_new = <span class="built_in">int</span>(np.<span class="built_in">round</span>(width_new / <span class="number">64.0</span>)) * <span class="number">64</span></span><br><span class="line">    height_new = <span class="built_in">int</span>(np.<span class="built_in">round</span>(height_new / <span class="number">64.0</span>)) * <span class="number">64</span></span><br><span class="line">    img = img.resize((width_new, height_new))</span><br><span class="line">    img = img.convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">    img.save(image_filename, <span class="string">&quot;PNG&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Resize image form <span class="subst">&#123;width&#125;</span>x<span class="subst">&#123;height&#125;</span> to <span class="subst">&#123;width_new&#125;</span>x<span class="subst">&#123;height_new&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># 这个模型用的是Salesforce/blip-image-captioning-base，从图片生成标题，生成结果会当作图片描述</span></span><br><span class="line">    <span class="comment"># 然后又有一段硬编码对话，继续引导ai使用工具来理解图片</span></span><br><span class="line">    description = self.models[<span class="string">&#x27;ImageCaptioning&#x27;</span>].inference(image_filename)</span><br><span class="line">    Human_prompt = <span class="string">&quot;\nHuman: provide a figure named &#123;&#125;. The description is: &#123;&#125;. &quot;</span> \</span><br><span class="line">    <span class="string">&quot;This information helps you to understand this image, &quot;</span> \</span><br><span class="line">    <span class="string">&quot;but you should use tools to finish following tasks, &quot;</span> \</span><br><span class="line">    <span class="string">&quot;rather than directly imagine from my description. If you understand, say \&quot;Received\&quot;. \n&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">        image_filename, description)</span><br><span class="line">    <span class="comment"># 帮ai回答 收到！</span></span><br><span class="line">    AI_prompt = <span class="string">&quot;Received.  &quot;</span></span><br><span class="line">    self.agent.memory.buffer = self.agent.memory.buffer + Human_prompt + <span class="string">&#x27;AI: &#x27;</span> + AI_prompt</span><br><span class="line">    state = state + [(<span class="string">f&quot;![](/file=<span class="subst">&#123;image_filename&#125;</span>)*<span class="subst">&#123;image_filename&#125;</span>*&quot;</span>, AI_prompt)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\nProcessed run_image, Input image: <span class="subst">&#123;image_filename&#125;</span>\nCurrent state: <span class="subst">&#123;state&#125;</span>\n&quot;</span></span><br><span class="line">          <span class="string">f&quot;Current Memory: <span class="subst">&#123;self.agent.memory.buffer&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">return</span> state, state, txt + <span class="string">&#x27; &#x27;</span> + image_filename + <span class="string">&#x27; &#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>工具</strong><br />里面用的工具都是各种模型功能，比如text2img，发送给LLM的内容就是name+description，之后如何LLM期望使用这个工具，就会调用inference来返回结果。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/1487474/1691812437310-26e656c8-dde2-429b-a283-d7a981f17655.png#averageHue=%23fefcfc&amp;clientId=u724c9408-4af4-4&amp;from=paste&amp;id=uc14525b7&amp;originHeight=1024&amp;originWidth=2268&amp;originalType=url&amp;ratio=1.5&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=uc1664fc4-fe09-4d33-ba8c-7d7e2a68b2c&amp;title=" alt="" /><br /><strong>可供使用的工具有如下（比刚看开始又多了）</strong></p>
<table>
<thead>
<tr>
<th><strong>Foundation Model</strong></th>
<th><strong>GPU Memory (MB)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>ImageEditing</td>
<td>3981</td>
</tr>
<tr>
<td>InstructPix2Pix</td>
<td>2827</td>
</tr>
<tr>
<td>Text2Image</td>
<td>3385</td>
</tr>
<tr>
<td>ImageCaptioning</td>
<td>1209</td>
</tr>
<tr>
<td>Image2Canny</td>
<td>0</td>
</tr>
<tr>
<td>CannyText2Image</td>
<td>3531</td>
</tr>
<tr>
<td>Image2Line</td>
<td>0</td>
</tr>
<tr>
<td>LineText2Image</td>
<td>3529</td>
</tr>
<tr>
<td>Image2Hed</td>
<td>0</td>
</tr>
<tr>
<td>HedText2Image</td>
<td>3529</td>
</tr>
<tr>
<td>Image2Scribble</td>
<td>0</td>
</tr>
<tr>
<td>ScribbleText2Image</td>
<td>3531</td>
</tr>
<tr>
<td>Image2Pose</td>
<td>0</td>
</tr>
<tr>
<td>PoseText2Image</td>
<td>3529</td>
</tr>
<tr>
<td>Image2Seg</td>
<td>919</td>
</tr>
<tr>
<td>SegText2Image</td>
<td>3529</td>
</tr>
<tr>
<td>Image2Depth</td>
<td>0</td>
</tr>
<tr>
<td>DepthText2Image</td>
<td>3531</td>
</tr>
<tr>
<td>Image2Normal</td>
<td>0</td>
</tr>
<tr>
<td>NormalText2Image</td>
<td>3529</td>
</tr>
<tr>
<td>VisualQuestionAnswering</td>
<td>1495</td>
</tr>
</tbody>
</table>
<p><a name="o0FCm"></a></p>
<h1 id="扩展阅读"><a class="markdownIt-Anchor" href="#扩展阅读"></a> 扩展阅读</h1>
<p><a name="ybCvl"></a></p>
<h2 id="langchain"><a class="markdownIt-Anchor" href="#langchain"></a> langchain</h2>
<p><a name="oJ6C1"></a></p>
<h3 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h3>
<p>LLM很强，但是单独使用这些 LLM 往往不足以创建一个真正强大的应用程序—当您将它们与其他工具结合时，真正的力量就来了。visual-chatgpt主要用到了langchain的**agents和memory（历史对话）**能力。<br />
<a name="vECxF"></a></p>
<h3 id="agent"><a class="markdownIt-Anchor" href="#agent"></a> <strong>agent</strong></h3>
<p>因为主要用了这个功能，简单讲一下这块的代码<br />核心调用入口在_call方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;Run text through and get agent response.&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># Do any preparation necessary when receiving a new input.</span></span><br><span class="line">self.agent.prepare_for_new_call()</span><br><span class="line"><span class="comment"># Construct a mapping of tool name to tool for easy lookup</span></span><br><span class="line">name_to_tool_map = &#123;tool.name: tool <span class="keyword">for</span> tool <span class="keyword">in</span> self.tools&#125;</span><br><span class="line"><span class="comment"># We construct a mapping from each tool to a color, used for logging.</span></span><br><span class="line">color_mapping = get_color_mapping(</span><br><span class="line">    [tool.name <span class="keyword">for</span> tool <span class="keyword">in</span> self.tools], excluded_colors=[<span class="string">&quot;green&quot;</span>]</span><br><span class="line">)</span><br><span class="line">intermediate_steps: <span class="type">List</span>[<span class="type">Tuple</span>[AgentAction, <span class="built_in">str</span>]] = []</span><br><span class="line"><span class="comment"># Let&#x27;s start tracking the iterations the agent has gone through</span></span><br><span class="line">iterations = <span class="number">0</span></span><br><span class="line"><span class="comment"># We now enter the agent loop (until it returns something).</span></span><br><span class="line"><span class="comment"># 进入循环，直到获取到结果，如果超出循环次数也会直接返回</span></span><br><span class="line"><span class="keyword">while</span> self._should_continue(iterations):</span><br><span class="line">    next_step_output = self._take_next_step(</span><br><span class="line">        name_to_tool_map, color_mapping, inputs, intermediate_steps</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 遇到中止识别，则返回最终结果，怎样算中止，可以看下一段代码</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(next_step_output, AgentFinish):</span><br><span class="line">        <span class="keyword">return</span> self._<span class="keyword">return</span>(next_step_output, intermediate_steps)</span><br><span class="line">    <span class="comment"># 否则会保存上一步的信息</span></span><br><span class="line">    intermediate_steps.append(next_step_output)</span><br><span class="line">    iterations += <span class="number">1</span></span><br><span class="line"><span class="comment"># 中止有特殊处理    </span></span><br><span class="line">output = self.agent.return_stopped_response(</span><br><span class="line">    self.early_stopping_method, intermediate_steps, **inputs</span><br><span class="line">)</span><br><span class="line"><span class="keyword">return</span> self._<span class="keyword">return</span>(output, intermediate_steps)</span><br></pre></td></tr></table></figure>
<p><strong>提取工具或是中止</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这个类型的中止标记是获取到ai的输出，例如ai:xxx</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">finish_tool_name</span>(<span class="params">self</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Name of the tool to use to finish the chain.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> self.ai_prefix</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_extract_tool_and_input</span>(<span class="params">self, llm_output: <span class="built_in">str</span></span>) -&gt; <span class="type">Optional</span>[<span class="type">Tuple</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]]:</span><br><span class="line">    <span class="comment"># 如果获取到了ai的回答则中止</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">f&quot;<span class="subst">&#123;self.ai_prefix&#125;</span>:&quot;</span> <span class="keyword">in</span> llm_output:</span><br><span class="line">        <span class="keyword">return</span> self.ai_prefix, llm_output.split(<span class="string">f&quot;<span class="subst">&#123;self.ai_prefix&#125;</span>:&quot;</span>)[-<span class="number">1</span>].strip()</span><br><span class="line">    <span class="comment"># 否则提取应该使用的工具</span></span><br><span class="line">    regex = <span class="string">r&quot;Action: (.*?)[\n]*Action Input: (.*)&quot;</span></span><br><span class="line">    <span class="keyword">match</span> = re.search(regex, llm_output)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">match</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Could not parse LLM output: `<span class="subst">&#123;llm_output&#125;</span>`&quot;</span>)</span><br><span class="line">    action = <span class="keyword">match</span>.group(<span class="number">1</span>)</span><br><span class="line">    action_input = <span class="keyword">match</span>.group(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> action.strip(), action_input.strip(<span class="string">&quot; &quot;</span>).strip(<span class="string">&#x27;&quot;&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>顺便再贴一下默认的咒语</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># flake8: noqa</span></span><br><span class="line">PREFIX = <span class="string">&quot;&quot;&quot;Assistant is a large language model trained by OpenAI.</span></span><br><span class="line"><span class="string">Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.</span></span><br><span class="line"><span class="string">Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.</span></span><br><span class="line"><span class="string">Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.</span></span><br><span class="line"><span class="string">TOOLS:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Assistant has access to the following tools:&quot;&quot;&quot;</span></span><br><span class="line">FORMAT_INSTRUCTIONS = <span class="string">&quot;&quot;&quot;To use a tool, please use the following format:</span></span><br><span class="line"><span class="string">​```</span></span><br><span class="line"><span class="string">Thought: Do I need to use a tool? Yes</span></span><br><span class="line"><span class="string">Action: the action to take, should be one of [&#123;tool_names&#125;]</span></span><br><span class="line"><span class="string">Action Input: the input to the action</span></span><br><span class="line"><span class="string">Observation: the result of the action</span></span><br><span class="line"><span class="string">​```</span></span><br><span class="line"><span class="string">When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:</span></span><br><span class="line"><span class="string">​```</span></span><br><span class="line"><span class="string">Thought: Do I need to use a tool? No</span></span><br><span class="line"><span class="string">&#123;ai_prefix&#125;: [your response here]</span></span><br><span class="line"><span class="string">​```&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">SUFFIX = <span class="string">&quot;&quot;&quot;Begin!</span></span><br><span class="line"><span class="string">Previous conversation history:</span></span><br><span class="line"><span class="string">&#123;chat_history&#125;</span></span><br><span class="line"><span class="string">New input: &#123;input&#125;</span></span><br><span class="line"><span class="string">&#123;agent_scratchpad&#125;&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p><a name="JvXkD"></a></p>
<h3 id="tools"><a class="markdownIt-Anchor" href="#tools"></a> tools</h3>
<p>langchain已经自带的工具列表，包括计算器，python shell，天气查询api，搜索api等<br />详细见：<a target="_blank" rel="noopener" href="https://langchain.readthedocs.io/en/latest/modules/agents/tools.html">https://langchain.readthedocs.io/en/latest/modules/agents/tools.html</a><br />
<a name="szvvE"></a></p>
<h2 id="llama_index"><a class="markdownIt-Anchor" href="#llama_index"></a> llama_index</h2>
<p><strong>咒语</strong><br /><img src="https://cdn.nlark.com/yuque/0/2023/png/1487474/1691812437241-c15d8c5f-b9ad-4078-bf8e-fa9763b8a10c.png#averageHue=%232b2b2b&amp;clientId=u724c9408-4af4-4&amp;from=paste&amp;id=u2582622d&amp;originHeight=376&amp;originWidth=1170&amp;originalType=url&amp;ratio=1.5&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ucbd44645-1922-4109-9d20-52f7db347d2&amp;title=" alt="" /><br />
<a name="K39bY"></a></p>
<h1 id="思考"><a class="markdownIt-Anchor" href="#思考"></a> 思考</h1>
<p>:::info<br />
✍️让LLM学会使用工具！<br />
:::<br />
这种形式看上去可以延伸出很多骚操作，例如当前LLM无法获取最新的时事信息，或是网页信息，只要结合工具，帮他去获取信息从而给他分析，new bing就通过将搜索结果结合GPT4来分析；再比如visual-chatgpt通过结合各种图像模型，让LLM获取视觉能力。<br />
<a name="kvCE1"></a></p>
<h1 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h1>
<p><a target="_blank" rel="noopener" href="https://github.com/microsoft/visual-chatgpt">https://github.com/microsoft/visual-chatgpt</a><br /><a target="_blank" rel="noopener" href="https://github.com/hwchase17/langchain">https://github.com/hwchase17/langchain</a><br /><a target="_blank" rel="noopener" href="https://github.com/jerryjliu/llama_index">https://github.com/jerryjliu/llama_index</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">fish</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://fishx233.github.io/2023/03/09/visual-chatgpt源码分析/">https://fishx233.github.io/2023/03/09/visual-chatgpt源码分析/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2023/04/10/Go%20map%E5%AE%9E%E7%8E%B0/"><i class="fa fa-chevron-left">  </i><span>Go Map实现</span></a></div><div class="next-post pull-right"><a href="/2023/02/22/Kratos%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"><span>kratos源码分析</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(/media/101485281_p0_master1200.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2024 By fish</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.1"></script><script src="/js/fancybox.js?version=1.9.1"></script><script src="/js/sidebar.js?version=1.9.1"></script><script src="/js/copy.js?version=1.9.1"></script><script src="/js/fireworks.js?version=1.9.1"></script><script src="/js/transition.js?version=1.9.1"></script><script src="/js/scroll.js?version=1.9.1"></script><script src="/js/head.js?version=1.9.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>